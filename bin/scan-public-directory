#!/usr/bin/python3 -u
# -*- coding: utf-8 -*-

import argparse
import os
import os.path
import re
import sys
import urllib
import urllib.request
import urllib.parse
import shutil
import datetime
import yaml
import fnmatch
from signal import signal, SIGPIPE, SIG_DFL
signal(SIGPIPE, SIG_DFL)


# RAF 
# fmt

def readconf(configfile):
    path = os.path.expanduser(configfile)
    if not os.path.exists(path):
        with open(path, 'w', encoding='utf-8') as fd:
            print('Create a default configuration file.', file=sys.stderr)
            fd.write('''dir_regex: '<a href="([^"]*/)">[^<]*</a>'
a_regex: '<a [^>]*href="([^"]*[^\/])"[^>]*>[^<]*</a>'
clean_line:
  - "\\\\s*<img[^>]+>\\\\s*"
  - "\\\\s*<a[^>]+>[^<]*</a>\\\\s*"
  - "\\\\s*<td[^>]*>\\\\s*"
  - "\\\\s*<tr[^>]*>\\\\s*"
  - "\\\\s*</td>\\\\s*"
  - "\\\\s*</tr>\\\\s*"
  - "\\\\s*</tbody>\\\\s*"
  - "\\\\s*</body>\\\\s*"
  - "\\\\s*</table>\\\\s*"
  - "\\\\s*</html>\\\\s*"
  - "&nbsp;"
formats:
  - "DD-MMM-YYYY HH:mm"
  - "YYYY-MMM-DD HH:mm"
  - "M/D/YYYY h:mm A"
  - "YYYY-MM-DD HH:mm"
  - "dddd, MMMM DD, YYYY h:mm A"
a2strptime:
  'dddd': '%A'
  'ddd': '%a'
  'DD': '%d'
  'D': '%d'
  'MMMM': '%B'
  'MMM': '%b'
  'MM': '%m'
  'M': '%m'
  'YYYY': '%Y'
  'HH': '%H'
  'H': '%H'
  'hh': '%I'
  'h': '%I'
  'A': '%p'
  'a': '%p'
  'mm': '%M'
  'm': '%M'
aliases:
  :wget: "wget -c '{url}'"
''')
    with open(path, 'r', encoding='utf-8') as stream:
        return yaml.load(stream)


def print_err(verbose, text):
    if not verbose:
        print(text, file=sys.stderr)


def read_url(verbose, urlopener, url, encoding='latin1'):
    url = url.replace('&amp;', '&')
    print_err(verbose, ':: read ' + url)
    try:
        if urlopener is None:
            response = urllib.request.urlopen(url)
        else:
            response = urlopener.open(url)
        content = response.read()
        return content.decode(encoding)
    except Exception as e:
        print(e, file=sys.stderr)
        raise Exception('Error while trying to read url %s' % url)


def size_str_2_int(s):
    if s[-1] == 'k':
        return int(float(s[:-1])*1024)
    elif s[-1] == 'M':
        return int(float(s[:-1])*1024*1024)
    else:
        return int(s)


def humanize_size(s):
    if re.match('^\d+$', s):
        (s, x) = (int(s), '')
        if s >= 1024:
            s //= 1024
            x = 'k'
        if s >= 1024:
            s //= 1024
            x = 'M'
        return '%d%s' % (s, x)
    return s


class Conf:
    
    def __init__(self, dir_regex, a_regex, date_fmt, line_sep):
        self.DIR_REGEX = re.compile(dir_regex, re.IGNORECASE)
        self.A_REGEX = re.compile(a_regex, re.IGNORECASE)
        self.LINE_SEP = line_sep
        self.DATE_FMT = date_fmt
        self.DATE_REGEXP = re.compile(a2regexp(date_fmt), re.IGNORECASE)

    def a_regexp(self):
        return self.A_REGEX

    def dir_regexp(self):
        return self.DIR_REGEX

    def date_regexp(self):
        return self.DATE_REGEXP

    def date_strptime(self):
        if self.DATE_FMT:
            return a2strptime(self.DATE_FMT)
        else:
            return None


def range_padded(s, n, l=2):
    return '(' + '|'.join([str(x).zfill(l) for x in range(s, n+1)]) + ')'


def a2regexp(f):
    m = {
        'DD': range_padded(1, 31),
        'D': range_padded(1, 31, 1),
        'dddd': '([a-zA-Z])+',
        'ddd': '([a-zA-Z])+',
        'd': range_padded(1, 7, 1),
        'MMMM': '([a-zA-Z])+',
        'MMM': '([a-zA-Z])+',
        'MM': range_padded(1, 12),
        'M': range_padded(1, 12, 1),
        'YYYY': '([12][0-9]{3})',
        'HH': range_padded(0, 23),
        'H': range_padded(0, 23, 1),
        'hh': range_padded(1, 12),
        'h': range_padded(1, 12, 1),
        'A': '(AM|PM)',
        'a': '(am|pm)',
        'mm': range_padded(0, 59),
        'm': range_padded(0, 59, 1),
        ' ': '\s+',
        ',': '\s*,\s*'
    }
    pattern = '|'.join(sorted(m, reverse=True))
    repl = lambda matchobj: m[matchobj.group(0)]
    line = re.sub(pattern, repl, f)
    return line


def a2strptime(f):
    keys = [(len(x), x) for x in A2STRPTIME]
    keys.sort()
    keys.reverse()
    return re.sub('|'.join([b for a, b in keys]), lambda matched_obj: A2STRPTIME[matched_obj.group(0)], f)


def detect_conf(page):
    page = page.replace('\n', '')
    date_fmt = next((fmt for fmt in FORMATS if re.search(a2regexp(fmt), page, re.IGNORECASE)), None)
    if date_fmt is None:
        print('Date format not detected.', file=sys.stderr)
        sys.exit(1)
    if re.match('.*</a><br>.*', page, re.IGNORECASE):
        line_sep = '<br>'
    elif re.match('.*</a></td>.*', page, re.IGNORECASE):
        line_sep = '<tr>'
    else:
        line_sep = '\n'
    return Conf(DIR_REGEX, A_REGEX, date_fmt, line_sep)


def fix_url(url, current_url=None):
    if current_url:
        url = urllib.parse.urljoin(current_url, url)
    try:
        parsed = urllib.parse.urlparse(url)
        qs = urllib.parse.parse_qs(parsed.query)
        for k, v in qs.items():
            if isinstance(v, list) and len(v) == 1:
                qs[k] = v[0].encode("latin-1")
        parsed_as_list = list(parsed)
        parsed_as_list[4] = urllib.parse.urlencode(qs)
        return urllib.parse.urlunparse(parsed_as_list)
    except Exception:
        return url


PARENT_DIRECTORY = re.compile('Parent Directory|<a href="\\.\\./">\\.\\./</a>', re.I)
LAST_MODIFIED = re.compile('Last modified', re.I)


def parse_url(depth, url, conf=None, count=1):
    page = read_url(namespace.verbose, None, url)
    if not PARENT_DIRECTORY.search(page):
        print_err(namespace.verbose, 'no parent directory line')
        return
    if conf is None:
        conf = detect_conf(page)
    for line in page.split(conf.LINE_SEP):
        if namespace.debug:
            print()
            print("line", line)
        if PARENT_DIRECTORY.search(line) or LAST_MODIFIED.search(line):
            continue
        search = conf.dir_regexp().search(line)
        if search:
            line = search.group(1)
            to_url = fix_url(line, url)
            if namespace.max_depth is not None and (depth + 1 > namespace.max_depth):
                print_err(namespace.verbose, ':: max depth reached; ignore ' + to_url)
            elif 'http://' not in line:
                count = parse_url(depth+1, to_url, conf, count)
            continue
        search = conf.a_regexp().search(line)
        if namespace.debug:
            print("search", search)
        date = conf.date_regexp().search(line)
        if date:
            date = date.group(0)
            if namespace.debug:
                print("date", date)
        if search and date:
            to_url = search.group(1)
            href = fix_url(to_url, url)
            if namespace.debug:
                print(href)
            for regex in CLEAN_LINE:
                line = regex.sub('', line)
            line = line.replace(date, '')
            size = line.strip()
            if namespace.debug:
                print("size", size)
            if check_entry(date, size, href, conf, depth):
                if is_between_lines(count):
                    date = datetime.datetime.strptime(date, conf.date_strptime())
                    date = date.strftime('%Y-%m-%d %H:%M')
                    size = humanize_size(size)
                    execute(date, size, href, count)
                else:
                    print_err(namespace.verbose, ":: not in range (#" + str(count) + "); ignore " + to_url)
            count += 1
    return count


def print_separator(text):
    columns = shutil.get_terminal_size().columns
    print('/' * columns, file=sys.stderr)
    print('// ' + text + ' ' + '/' * (columns - len(text) - 5), file=sys.stderr)
    print('/' * columns, file=sys.stderr)
    print('', file=sys.stderr)


def execute(date, size, href, count):
    if any([namespace.print, namespace.exec, namespace.banner]):
        if namespace.banner:
            print_separator('#{index} {date} [{size}] {url}'.format(index=count, size=size, date=date, url=href))
        if namespace.print:
            print(namespace.print.format(index=count, size=size, date=date, url=href, file=sys.stdout))
        if namespace.exec:
            command = namespace.exec
            if command[0] == ':':
                command = yamldoc['aliases'][command]
            import shlex
            import subprocess
            l = [x.format(index=count, size=size, date=date, url=href) for x in shlex.split(command)]
            subprocess.call(l)
    else:
        print(date + '|' + size + '|' + href)


def size_string(v):
    try:
        return re.match("^\d+(\.\d+)?[kM]?", v).group(0)
    except:
        raise argparse.ArgumentTypeError("String '%s' does not match required format" % (v,))


def url_matches(href, element):
    for x in element.split(','):
        if any(y in x for y in ('*', '?', '[', ']')):
            r = fnmatch.fnmatch(href, x)
        else:
            r = href.endswith('.' + x)
        if r:
            return True
    return False


def check_entry(date, size, href, conf, depth):
    if namespace.accept is not None:
        ok = url_matches(href, namespace.accept)
        if not ok:
            print_err(namespace.verbose, ':: extension/pattern not accepted; ignore ' + href) 
            return 0
    if namespace.reject is not None:
        ok = url_matches(href, namespace.reject)
        if ok:
            print_err(namespace.verbose, ':: extension/pattern not accepted; ignore ' + href) 
            return 0
    if namespace.min_size is not None:
        entry_size = size_str_2_int(size)
        min_size_expected = size_str_2_int(namespace.min_size)
        if entry_size < min_size_expected:
            print_err(namespace.verbose, ':: file too small [%s]; ignore %s' % (size, href)) 
            return 0
    if namespace.max_size is not None:
        entry_size = size_str_2_int(size)
        max_size_expected = size_str_2_int(namespace.max_size)
        if entry_size > max_size_expected:
            print_err(namespace.verbose, ':: file too large [%s]; ignore %s' % (size, href)) 
            return 0
    if namespace.min_depth is not None and depth < namespace.min_depth:
        print_err(namespace.verbose, ':: min depth not reached; ignore ' + href) 
        return 0
    if namespace.before is not None:
        entry_date = datetime.datetime.strptime(date, conf.date_strptime())
        max_date_expected = get_datetime(namespace.before)
        if entry_date > max_date_expected:
            print_err(namespace.verbose, ':: date [%s] after [%s]; ignore %s' % (entry_date, max_date_expected, href))
            return 0
    if namespace.after is not None:
        entry_date = datetime.datetime.strptime(date, conf.date_strptime())
        min_date_expected = get_datetime(namespace.after)
        if entry_date < min_date_expected:
            print_err(namespace.verbose, ':: date [%s] before [%s]; ignore %s' % (entry_date, min_date_expected, href))
            return 0
    return 1


def get_datetime(text):
    o = re.match("(\d+) day(s)? ago", text)
    if o:
        return datetime.datetime.now() - datetime.timedelta(int(o.group(1)))
    else:
        return datetime.datetime.strptime(text, '%Y-%m-%d %H:%M')


def is_between_lines(c):
    if namespace.lines is not None:
        o = re.match("(\d+)?(-)?(\d+)?", namespace.lines)
        if o.group(2) == '-':
            (start, end) = (o.group(1), o.group(3))
        else:
            (start, end) = (o.group(1), o.group(1))
        if (start is not None) and (c < int(start)):
            return False      
        if (end is not None) and (c > int(end)):
            return False
    return True


def parse_file(file, count=1):
    print_err(namespace.verbose, ':: read ' + file)
    with open(file, 'r') as fd:
        content = fd.read()
    conf = detect_conf(content)
    with open(file, 'r') as fd:
        for number, line in enumerate(fd):
            line = line[:-1]
            (date, size, href) = line.split('|', 3)
            if check_entry(date, size, href, conf, 0):
                if is_between_lines(number):
                    execute(date, size, href, count)
                    count += 1
                else:
                    print_err(namespace.verbose, ":: not in range (#" + str(count) + "); ignore " + href)


def check_date_detection(expected, line):
    conf = detect_conf(line)
    assert conf is not None
    date = conf.date_regexp().search(line)
    assert date is not None
    assert date.group(0) == expected
    

if False:
    check_date_detection('Monday, September 01, 2014  1:02 AM', '<br>   Monday, September 01, 2014  1:02 AM    123456 <A HREF="/somepath/somefile.txt">somefile</A>')
    check_date_detection('9/3/2014 11:09 AM', '<br>  9/3/2014 11:09 AM    123456 <A HREF="/somepath/somefile.txt">somefile</A>')
    sys.exit(0)


parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter,
                                 add_help=True,
                                 description='Scan Public Directory tool')

subparsers = parser.add_subparsers(help='Help for sub-command', dest='command')

parser_url = subparsers.add_parser('url', help='Scan an url and follow links to create a file containing urls')
parser_url.add_argument('url', metavar='URL', type=str, nargs=1, help='The url where performing operation')

parser_file = subparsers.add_parser('file', help='Scan a file containing urls to filter items')
parser_file.add_argument('file', metavar='FILE', type=str, nargs=1, help='The file on which perform operation')

for a_parser in [parser_url, parser_file]:
    a_parser.add_argument('--max-depth', metavar='LEVELS', type=int, help='Descend at mots levels')
    a_parser.add_argument('--min-depth', metavar='LEVELS', type=int, help='Ignore file links at levels less than levels')
    a_parser.add_argument('--min-size', metavar='SIZE', type=size_string, help='Ignore file with size less than the specified size')
    a_parser.add_argument('--max-size', metavar='SIZE', type=size_string, help='Ignore file with size greater than the specified size')
    a_parser.add_argument('--accept', metavar='LIST', type=str, help='Accept only the files with the specified file name suffixes or patterns (comma separated list). If any of the wildcard characters, *, ?, [ or ], appear in an element of the list, it will be treated as a pattern, rather than a suffix')
    a_parser.add_argument('--reject', metavar='LIST', type=str, help='Reject the files with the specified file name suffixes or patterns (comma separated list). If any of the wildcard characters, *, ?, [ or ], appear in an element of the list, it will be treated as a pattern, rather than a suffix')
    a_parser.add_argument('--verbose', help='Display more messages', action='store_false')
    a_parser.add_argument('--debug', help='Debug', action='store_true')
    a_parser.add_argument('--after', metavar='DATETIME', type=str, help='Reject the files with date/time before the specified datetime (YYYY-MM-DD hh:mm)')
    a_parser.add_argument('--before', metavar='DATETIME', type=str, help='Reject the files with date/time after the specified datetime (YYYY-MM-DD hh:mm)')
    a_parser.add_argument('--lines', metavar='LINES', type=str, help='Select specified lines matching all filters (N, N-, N-M, -M)')
    a_parser.add_argument('--banner', help='Display banner ', action='store_true')
    a_parser.add_argument('--print', metavar='FORMAT', type=str, help='Print the given string replacing patterns {index} {date} {size} {url} by their respective values')
    a_parser.add_argument('--exec', metavar='COMMAND', type=str, help='Execute the given shell command (ex: echo "#{index} {date} // {size} // {url}"). If command starts with : it is considered as an alias')


yamldoc = readconf('~/.spdrc')

CLEAN_LINE = [re.compile(x, re.IGNORECASE) for x in yamldoc["clean_line"]]
FORMATS = yamldoc['formats']
A2STRPTIME = yamldoc['a2strptime']
DIR_REGEX = yamldoc['dir_regex']
A_REGEX = yamldoc['a_regex']


if len(sys.argv) == 1:
    parser.print_help()
    sys.exit(1)


namespace = parser.parse_args()
try:
    if namespace.command == 'url':
        parse_url(0, namespace.url[0] + ('/' if not namespace.url[0].endswith('/') else ''))
    else:
        parse_file(namespace.file[0])
except KeyboardInterrupt:
    print('Interrupted.', file=sys.stderr)


